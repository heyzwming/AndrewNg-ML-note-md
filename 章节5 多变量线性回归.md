章节5 多变量线性回归(Multivariate Linear Regression))
===

## 课时27  多功能(Multiple Features)    08:22

假设我们有多个特征值和更多可以用来预测价格的信息，我们使用x_1 x_2 x_3 x_4来表示我们的四个特征，y来表示我们想要预测的房屋的输出变量(价格)

我们用
m：样本的数量
n：特征的数量
x^i：第i个训练样本的输入特征值(它是个向量，存放着所有特征量的值)
x_j^i：第i个训练样本中第j个特征量的值

![27.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/ISAgi8az8axPHsP7Gi0PsScijNmY00nPWmL7xe4AFZ4!/b/dN0AAAAAAAAA&bo=LQRcAgAAAAARF1c!&rf=viewer_4)

我们有多个特征量和的假设形式应该是怎样的？
h_θ(x) = θ_0+θ_1 * x_1+θ_2 * x_2+θ_3 * x_3+θ_4 * x_4
![gongshi](http://m.qpic.cn/psb?/V12umJF70r2BEK/iH2O7kxks5kCD9jYHIecdvPDzoHALTQUiuAjPbyyy2Y!/b/dAsBAAAAAAAA&bo=yAJDAAAAAAARF6k!&rf=viewer_4)
![27.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/U8.r9PTZg8ajelATxg5Tc6qpITOevWet*pCUcs.40Ww!/b/dN4AAAAAAAAA&bo=KQQ*AgAAAAARFzA!&rf=viewer_4)

为了符号方便，我们定义了额外的第0个特征向量x_0，并且它的取值总是1

由θ向量转置 内积 x向量的形式，为我们提供了一个便利的方式来表示假设，即用参数向量θ以及特征向量x的内积
![27.3](http://m.qpic.cn/psb?/V12umJF70r2BEK/osbaO999aOOp61Ju5GW*6B.K4Eb1LAx5l2lVwSj48XM!/b/dPQAAAAAAAAA&bo=SARAAgAAAAARBz4!&rf=viewer_4)

这就是在多特征量的情况下的假设形式，它就是所谓的多元线性回归(Multivariate linear regression)


## 课时28  多元梯度下降法(Gradient Descent for Multiple)    05:04


我们把参数θ看成是一个有关θ的 n+1维向量
J 看成 参数θ这个向量的函数
![28.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/QW*fG3zKgqiQ7N.0rQ3pTfGZ1BGY4f.xf8OdptGQi94!/b/dN8AAAAAAAAA&bo=NQRwAgAAAAARB3M!&rf=viewer_4)
我们的梯度下降算法也得到了更新：用于多元线性回归的梯度下降算法
![28.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/QW*fG3zKgqiQ7N.0rQ3pTfGZ1BGY4f.xf8OdptGQi94!/b/dN8AAAAAAAAA&bo=NQRwAgAAAAARF2M!&rf=viewer_4)

## 课时29  多元梯度下降法演练 I – 特征缩放(Gradient Descent in Practice Ⅰ - Feature Scaling)   08:52


## 课时30  多元梯度下降法II – 学习率(Gradient Descent in Practice Ⅱ - Learning Rate ) 08:58


## 课时31  特征和多项式回归(Features and Polynomial)  07:39


## 课时32  正规方程（区别于迭代方法的直接解法）(Normal Equation)  16:17


## 课时33  正规方程在矩阵不可逆情况下的解决方法(Normal Equation Noninvertibility)  05:59


## 课时34  完成并提交编程作业(Working on and Submitting Programming Assignments)    03:33


