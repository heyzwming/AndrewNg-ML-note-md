十五、Anomaly Detection(异常检测)
===
### Density Estimation()
---
## 15.1、 Problem Motivation(问题规划)

异常检测(Anomaly detection)问题是机器学习算法的一个常见应用 这种算法的一个有趣之处在于它虽然主要用于非监督学习问题 但从某些角度看它又类似于一些监督学习问题 

![15.1.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/TchjYRzgfAMn7uQbHCv6FghqF*l.ZRkQhjtRLysCnCI!/b/dPQAAAAAAAAA&bo=ggPxAQAAAAARF1E!&rf=viewer_4)

那么什么是异常检测呢？举个例子，假设你是一个飞机引擎制造商，当你生产的飞机引擎从生产线上流出时 你需要进行 QA (质量控制测试) ，而作为这个测试的一部分，你测量了飞机引擎的一些特征变量，如引擎运转时产生的热量或者引擎的振动等等,这样一来你就有了一个数据集,从$x_{(1)}$到$x_{(m)}$.将这些数据绘制成图表,看起来就是这个样子,这里的每个叉都是你的无标签数据.

这样 异常检测问题可以定义如下 

我们假设后来有一天你有一个新的飞机引擎从生产线上流出,而你的新飞机引擎有特征变量集$x_test$,所谓的异常检测问题就是我们希望知道这个新的飞机引擎是否有某种异常，或者说我们希望判断这个引擎是否需要进一步测试 

如果你的新引擎对应的点落在绿色的这个点，那么你可以认为它看起来像我们之前的合格的引擎，因此我们可以直接认为它是正常的 然而 如果你的新飞机引擎对应的点$x_test$在这群点的外面 那么我们可以认为这是一个异常 

也许我们需要在向客户发货之前进一步检测这个引擎,因为它和我们之前见过的其他正常飞机引擎看起来不一样 

如果更正式的定义异常检测问题 那么我们有一些数据 从x(1)到x(m) 我们通常假定这m个样本 都是正常的 然后我们需要一个算法来告诉我们 一个新的样本数据x-test是否是异常 我们要采取的方法是给定无标签的训练集 我们将对数据建一个模型p(x) 也就是说 我们将对 x的分布概率建模 其中x是这些特征变量 例如飞机引擎 

![15.1.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/txLwzHRQTeTzjjcfJP4RtMRyYJ0pOet.YJXcCORLIXA!/b/dG0BAAAAAAAA&bo=sAPsAQAAAAARF34!&rf=viewer_4)

因此 当我们 建立了x的概率模型之后 我们就会说 对于新的飞机引擎x-test 如果概率p 低于阈值ε 那么就将其标记为异常 

因此当我们看到一个新的引擎 在我们根据训练数据得到的p(x)模型中 这个点出现的概率非常低时 我们就将其标记为异常 反之 如果x-test的概率p 大于给定的阈值ε 我们就认为它是正常的 

因此 给定图中的 这个训练集 如果你建立了一个模型 你将很可能发现飞机引擎，即模型p(x) 将会认为 在中心区域的这些点 有很大的概率值是正常的，而稍微远离中心区域的点正常的概率会小一些 

更远的地方的点 它们的概率将更小 这外面的点 和这外面的点 将成为异常点 

而这边的点 正好在中心区域的点 这些点将是正常的 因为在中心区域 p(x)概率值会非常大 因为我们看到很多点都落在了这个区域 

异常检测算法有如下应用案例 

![15.1.3](http://m.qpic.cn/psb?/V12umJF70r2BEK/sx2uNH3yHBDf8ArZRRLZBLd6a5SFUYNHJti0xpTBJIE!/b/dIABAAAAAAAA&bo=pgMCAgAAAAARF4U!&rf=viewer_4)

也许异常检测 最常见的应用是 是欺诈检测 假设你有很多用户 你的每个用户 都在从事不同的活动 也许是在你的网站上 也许是在一个实体工厂之类的地方 你可以对不同的用户活动计算特征变量 

然后你可以建立一个模型用来表示用户表现出各种行为的可能性,即用户行为对应的特征向量出现的概率 

因此你看到某个用户在网站上行为的特征变量是这样的 

也许x1是用户登陆的频率 x2也许是用户访问某个页面的次数 或者交易次数 也许x3是 用户在论坛上发贴的次数 x4是 用户的 打字速度 有些网站是可以记录 用户每秒 打了多少个字母的 因此你可以根据这些数据建一个模型p(x) 

最后你将得到 你的模型p(x) 然后你可以用它来发现 你网站上的行为奇怪的用户 你只需要 看哪些用户的p(x)概率小于ε 接下来 你拿来这些用户的档案 做进一步筛选 

或者要求这些用户 验证他们的身份 从而让你的网站防御 异常行为或者欺诈行为 

这样的技术将会找到 行为不寻常的用户 而不只是有欺诈行为的用户 也不只是那些 被盗号的用户 或者有滑稽行为的用户 而是行为不寻常的用户 然而这就是许多在线购物网站常用来识别异常用户的技术 这些用户行为奇怪 可能是表示他们有欺诈行为或者是被盗号 

异常检测的另一个例子是在工业生产领域 事实上 我们之前已经谈到过 飞机引擎的问题 你可以找到异常的飞机引擎 然后要求进一步细查这些引擎的质量 

第三个应用是 数据中心的计算机监控 实际上 我有些朋友正在从事这类工作 如果你管理一个 计算机集群 或者一个数据中心 其中有许多计算机 那么我们可以为每台计算机计算特征变量 也许某些特征衡量 计算机的内存消耗 或者硬盘访问量 CPU负载 或者一些更加复杂的特征 例如一台计算机的CPU负载与网络流量的比值 那么 给定正常情况下数据中心中计算机的特征变量 你可以建立p(x)模型 也就是说你可以建模这些计算机出现不同内存消耗的概率 或者出现不同硬盘访问量的概率 或者不同的CPU负载等等 

然后 如果你有一个计算机 它的概率p(x)非常小 那么你可以认为这个计算机运行不正常 

或许它 即将停机 因此你可以要求系统管理员查看其工作状况 

目前这种技术实际正在被各大数据中心使用 用来监测大量计算机可能发生的异常 

好啦 这就是异常检测算法 

在下一个视频中 我们将介绍一下高斯分布 回顾一下高斯分布 的一些特征 在再下一个视频中 我们将利用高斯分布来推导一个异常检测算法

## 15.2、 Gaussian Distribution(高斯分布)

在这个视频中 我将介绍高斯分布(the Gaussian distribution) 也称为正态分布(normal distribution)

假设x是一个 实数随机变量 因此x是一个实数 如果x的概率分布服从高斯分布,其中均值为μ ,方差为$σ^2$ 那么将它记作 随机变量x~

这个波浪号 读作 服从...分布 为了表示高斯分布 有时你将使用$N(,σ^2)$

高斯分布 有两个参数 一个是均值 我们记作$μ$ 另一个是方差我们记作$σ^2$

![15.2.1](http://m.qpic.cn/psb?/V12umJF70r2BEK/60jS1IC9Ay29xLg.rSIkBj7Wj*K0W5h6OPwJLaZ0fS8!/b/dOAAAAAAAAAA&bo=awPfAQAAAAARF5Y!&rf=viewer_4)

如果我们将高斯分布 的概率密度函数绘制出来 它看起来将是这样一个钟形的曲线 大家之前可能就见过 

这个钟形曲线 有两个参数 分别是μ和σ 其中μ控制 这个钟形曲线 的中心位置 σ控制这个钟形曲线的宽度 

因此 参数σ 有时也称作 一个标准差 

这条钟形曲线决定了x取不同数值的概率密度分布 

因此x取中心这些值的概率相当大 因为高斯分布的概率密度在这里很大 

而x取远处和更远处数值的概率将逐渐降低 直至消失 

高斯分布的数学公式的表示是这样的：
$$p(x|μ,σ^2) = \frac{1}{ (2\pi)^{\frac{1}{2}} \sigma} exp(-\frac{(x-μ)^2}{2\sigma^2})$$
 
左边这幅图的这条曲线其实就是给定$μ$以及$σ^2$,p(x)的函数图像 

也许有些时候我们使用方差会更方便 但有时候我们用σ^2，而σ被称作 标准差(the standard deviation) 它确定了 高斯分布概率密度函数 的宽度 而$σ^2$则称作方差 

让我们看几个高斯分布的图像 

![15.2.2](http://m.qpic.cn/psb?/V12umJF70r2BEK/PS6QDR7IvquZ*z1VKLv7jpsEjhMJoFZZ*EP*pY3XZn4!/b/dPQAAAAAAAAA&bo=YwPhAQAAAAARF6A!&rf=viewer_4)

如果μ取0 σ取1 那么这将对应一个以0为中心的高斯分布 而高斯分布的宽度 由标准差σ决定 

再看一些μ=0， σ=0.5、μ=0，σ=2的例子


接下来 让我们来看参数估计问题 

![15.2.3](http://a3.qpic.cn/psb?/V12umJF70r2BEK/ZUbDIzl6O*WVTKmv*SMvSfSVJwQPIfzfvfPktOtDyKU!/b/dN4AAAAAAAAA&ek=1&kp=1&pt=0&bo=nQX2AgAAAAARF0w!&tl=3&vuin=904260897&tm=1536289200&sce=60-2-2&rf=viewer_4)

那么 什么是参数估计问题？ 假设我们有一个有m个样本的数据集 从$x^{(1)}$到$x^{(m)}$ 假设他们都是实数 在这幅图里 我画出了整个数据集 图中的横轴 是x轴 我的样本x取值分布广泛 我就将它们画在这里 而参数估计问题就是 假设我猜测这些样本 来自一个高斯分布的总体 每一个样本xi服从某个分布 因此 我猜测这里的每个样本服从正态分布或者高斯分布 它有两个参数μ和σ平方 然而我不知道这些参数的值是多少 

参数估计问题就是给定数据集 我希望能找到能够估算出μ和σ平方的值 

因此如果你有这样一个数据,我试图找到它来自哪个高斯分布 

也许这个就是它对应的高斯分布 

其中μ对应分布函数的中心 而标准差σ控制高斯分布的宽度 这条曲线似乎很好的拟合了数据 因为看起来这个数据集 在中心区域的概率比较大 而在边缘的概率越来越小 因此 也许这是 对μ和σ平方 的一个不错的估计 也就是说 我们的数据对应这样一个高斯分布 

那么 接下来我将写下对μ和σ平方进行参数估计的标准公式 我们估计μ的方法是 对我的 所有样本 求平均值 μ就是平均值参数 因此 我将 使用我的训练集 使用我的m个样本 对它们取平均 这样我就得到了高斯分布的中心位置 

$$μ = \frac{1}{m}\sum^m_{i=1}x^{(i)}$$

那么如何估计σ平方呢？ σ平方表示方差 我们也来写下方差的标准计算公式 

$$\sigma^2 = \frac{1}{m}\sum^m_{i=1}(x^{(i)}-μ)^2$$

而方差的含义就是所有样本的差值平方和再求平均。

在极大似然估计(maximum likelihood estimation)里的估计 实际就是对μ和σ^2 的极大似然估计

如何估计高斯分布中的参数μ和σ平方 只要你有一个训练集 如果你猜测它来自一个高斯分布 你就可以估计出它的参数值μ和σ平方 



## 15.3、 Algorithm(算法)


在上节课的视频中 我们谈到了高斯分布 在本节视频中 我将应用高斯分布开发异常检测算法 

假如说我们有一个无标签的训练集 共有 m 个训练样本 并且 这里的训练集里的每一个样本 都是 n 维的特征 因此你的训练集应该是 

m 个 n 维的特征构成的样本矩阵 比如 m 个飞机引擎产品的样本 或者是 来自 m 个用户或者其它的什么东西 

现在 我们解决异常检测的方法是 我们要从数据中 建立一个 p(x) 概率模型 我们要尝试计算出这些哪些特征出现的概率比较高 哪些特征的概率较低 因此 x 是一个向量 我们要做的事情是 建立一个 p(x) 的模型 表示 x1 的概率 这是 x 的第一个组成部分 并用它乘以 x2 的概率 这是第二个特征的概率 然后再乘以 第三个特征的概率 一直这样下去 直到最后一个特征 xn 直到最后一个特征 xn 这里我先空着 最后再来填满 

那么 我们如何为这些项进行建模呢？ p(x1) p(x2) 等等 

我们下面要做的 是假定特征 x1 其分布 服从高斯正态分布 你也可以 写出期望 μ1 以及方差 我用 σ1 的平方表示 

这样 p(x1) 就可以写成 这样一个高斯分布 其期望为 μ1 方差为 (σ1)^2 同样地 我假设 x2 也服从高斯分布 这里的小波浪线读作"服从"  表示它服从高斯分布 其期望为 μ2 方差为 (σ2)^2 所以它服从的高斯分布与刚刚那个不同 它的期望和方差都不一样 与此类似 x3 服从另外一个高斯分布 因此 x3 也会有一个不同的期望 以及一个与其它特征不同的标准差 直到 xn 都是如此 

这就是我要说的模型 

顺便说一下 对那些擅长统计的同学来说 实际上 我刚刚写的式子 写出来实际上就对应于 一个从 x1 到 xn 上的独立的假设 一个从 x1 到 xn 上的独立的假设 但实际中 结果是 这些算法的效果都还不错 无论这些特征 是否独立 即使这个独立的假设不成立 这个算法的效果也还不错 如果你不知道 我刚刚提到的独立事件和其它相关内容 也不要担心 你将会慢慢有能力去理解 并且能很好地实现这些算法 刚才插入的那些内容也不重要 

最后 做一个总结 让我把这些式子写得紧凑点 我可以把这个式子 写成一个乘积式 从 j=1 到 j=n 从 j=1 到 j=n 乘积项是 p(xj; μj, (σj)^2) 也就是 n 个概率的乘积 

在这里 出现了一个有趣的符号 希腊字母 Π 这个有趣的字母表示的是 一系列数值的乘积 同时 你应该对求和符号比较熟悉 从 i=1 到 n 求和 也就是 1+2+3+... 直到加到 n 因此刚才的符号 Π 正如这个求和符号 ∑ 一样 只是表示从 i 等于1 到 n 进行连乘 那么 这里的 Π 用法一样 只不过表示连乘而不是连加 这就变成了 1×2×3 一直乘到 n 

所以这里用的就是 这里连乘的符号 这个表达式表示从等于 j=1 开始一直乘到 j=n 这样写看起来更紧凑 这样写只是避免了 把这个乘积表达式 的所有项都写出来而已 因为我们需要把 所有的 p(xj; μj, (σj)^2) 项 全部乘起来 同时 

顺便要说的是 估计 p(x) 的分布问题 这种问题通常被称为 

密度估计问题 正如幻灯片的标题上写的 

把所有的结合起来 下面便是我们的异常检测算法 

第一步便是选择特征 或者是找出一些 我们认为的具有比较反常样本 的特征 xi 我的意思是 我们可以尝试 找出一些特征 这些特征能看出比如 在你的系统里有一些不同寻常的用户 可能可以看出他们的反常或欺诈行为 或者是那个飞机引擎的例子 在飞机的众多引擎里有一个奇怪的引擎 选出这种特征 xi 这个特征可能会 

呈现一个特别大的数值 或者特别小的数值 因为这个看起来本身就有些异常 但更为普遍的是 尽可能尝试选择能够 

描述数据相关的属性的特征 接下来 给出一组  m 个无标签数据构成的训练集 

从 x(1) 到 x(m) 我们要拟合出 期望 μ1 到 μn 以及方差值 (σ1)^2 到 (σn)^2 同时 这些公式 和之前视频里的 公式是类似的 因此 我们便可以 估计这些参数的值 我们再说得详细一点 μj 是特征 j 的平均值 因此 μj 对应的模型 就是 p(xj; μj, (σj)^2) 就是 p(xj; μj, (σj)^2) 因此 μj 就相当于 对特征 j 的 所有训练集数据取平均值 同时  正如我刚才所讲 你需要对 j 从1到n 计算这些概率值 也就是说用这些公式来估计 μ1 再估计 μ2 直到 μn 同样地 对于 σ^2 也一样 同时 用向量化的方法也可以写出来 所以 你可以把 你把 μ 假想成一个向量 那么向量 μ 就有 μ1 μ2 直到 μn 那么 这个公式的向量表示形式 就能被写出来 μ 的值等于 x(i) 的值 从 i = 1 到 n 求和 再乘以 1/m 因此我刚刚写出的公式 还是用来估计 μ 的值 其中 x(i) 是一系列特征组成的向量 同时包含了所有 n 个值 

同样地 我们也可以 写出估计 (σj^2) 的 向量化的公式 

最后 当给出一个新样本时 比如当有一个新的飞机引擎时 你想要知道这个飞机引擎是否出现异常 

我们要做的就是 计算出 p(x) 的值来 那么这个案例中的概率是多少呢 

我们知道 p(x) 的值 等于这个乘积式 你现在 需要用这个公式计算 而这一项 就是乘积项 就是在计算高斯概率 所以你需要计算出这一项 然后看看 如果这个概率值很小 那么你就将这一项标注为异常 

这就是我们应用这种方法的一个案例 

假如说我们有一系列数据 就是在幻灯片左上角绘制的数据集 

让我们看这个特征 x1 如果你看到这个数据集 你会发现它看起来比较平均 x1 这个特征的均值大约是5 

并且也有一个标准差 如果你只看 数据集中 x1 的值 其标准差可能为2 所以这一段就是 σ1 然后你再来看第二个特征 从纵轴测量的 特征 x2 看起来其平均值 可能是3 且其标准差值大约为1 如果你使用这个数据集 且如果你估计出 μ1 μ2 σ1 σ2 你就会得到这样的结果 再次说明一下 我在这里写的 σ 表示的是标准差 但先前的公式里给出的 实际上可以将这些项的平方(也就是方差) 也即得到的是σ1的平方 σ2的平方 所以你要仔细一点 注意一下到底在使用σ1 σ2 还是 σ1 σ2 的平方 所以 σ1的平方的值当然等于4 

就是 2的平方 在图上 以 μ1 σ1^2  为参数的 p(x1; μ1,σ1^2) 和以 μ2 σ2 为参数的 为参数的 p(x2; μ2,σ2^2) 呈现出像这样的两个分布 

实际上 如果绘制 p(x) 的图像 也就是 这两个概率值的乘积 事实上 你会得到一个这样的立体图像 这就是 p(x) 值的图像 我们可以得出 具体的某一点 对应的高度值 给出一个具体的 x1 和 x2 的值 假如 x1 等于2  x2 也等于2 那么就是这个点 在3-D表面图上的高度 就表示 p(x) 值 

所以 p(x) 就是这个图的高度 完整地写出来 这个 p(x) 的值等于  

p(x1; μ1,σ1^2)  乘以 p(x2; μ2,σ2^2) p(x2; μ2,σ2^2) 现在 我们就知道了如何从数据拟合参数 让我们看看一些新的样本 假如在这里我们有了一个新样本 

我要知道这个样本是否异常 或许我还有另一个样本 比如我在这里有第二个新样本 这个样本又是否异常呢? 要回答这个问题 我们可以先给计算机设某个无穷小的数值 假如我设置的 无穷小量数值为0.02 我会在后面讲到如何选取 ε 的值 

不过 我们先看第一个样本 我们把这个称为 x(1)test 同时 

称第二个样本为 x(2)test 我们现在要做的 是计算 p(x(1)test) 我们用上面这个公式 就能计算出来 不难发现这是一个相当大的数 具体地 这个值可能大于 或者大于等于 ε 值 相较于计算机的无穷小量 ε 这个数值是比较大的 所以我们说 x1 检测的结果是 不是异常 

然而 如果你计算 p(x(2)test) 会是一个更加小的数 比 ε 还要小很多 那么我们会说 x2 确实是一个异常数值 因为那已经远远小于了先前我们定义的 ε 值 

但事实上 我们也可以对这个方法进行改进 看这个三维表面图 

从图上不难发现 在这个图的中间部分的x1 x2 通常都对应于 一个比较高的表面值 预示着非异常样本 或者正常样本 而在周围边缘的点 这些桃红色的区域 所有这些区域 对应的概率值 都是非常小的 因此我们会标记这些点 为异常样本区域 所以 我们也许可以 定义某个区域 像这样 在这个外面的 标记为异常区域 

而在这个里面的 可以标记为非异常区 表示无异常的样本 所以这个测试样本 x(2)test 处于无异常区之外 也就是说 它所对应的概率值很小 因此认为它是一个异常样本 

在这段视频中 我们介绍了如何拟合 p(x) 也就是 x 的概率值 以开发出一种异常检测算法 

同时 在这节课中 我们也给出了 通过给出的数据集 拟合参数 进行参数估计 得到参数 μ 和 σ 然后检测新的样本 确定新样本是否是异常 这一系列完整的过程 

在接下来的课程中 我们将深入研究这一算法 同时更深入地介绍 怎样让算法工作地更加有效 


### Building an Anomaly Detection System()
---
## 15.4、 Developing and Evaluating an Anomaly Detection System(开发和评估异常检测系统)


在上一段视频中 我们推导了异常检测算法 在这段视频中 我想介绍一下 如何开发一个 关于异常检测的应用 来解决一个实际问题 具体来说 我们将重点关注如何评价一个异常检测算法 在前面的视频中 我们已经提到了 使用实数评价法的重要性 这样做的想法是 当你在用某个学习算法 来开发一个具体的 机器学习应用时 你常常需要做出很多决定 比如说 选择用什么样的特征 等等 而如果你找到某种 评价算法的方式 直接返回一个数字 来告诉你算法的好坏 那么你做这些决定就显得更容易了 

所以比如你要决定 

现在有一个额外的特征 我要不要把这个特征考虑进来？ 如果你带上这个特征 运行你的算法 再去掉这个特征运行你的算法 然后得到某个返回的数字 这个数字就直接告诉你 这个特征到底是让算法表现变好了还是变差了 这样 你就有了一种更好 更简单的方法 来确定是不是应该加上这个特征 

为了更快地 开发出一个 异常检测系统 那么最好能找到某种 评价异常检测系统的方法 

为了做到这一点 为了能评价一个 异常检测系统 我们先假定已有了一些带标签的数据 所以 我们要考虑的 异常检测问题 是一个非监督问题 使用的是无标签数据 但如果你有一些 带标签的数据 能够指明哪些是异常样本 哪些是非异常样本 那么这就是我们要找的 能够评价异常检测算法的标准方法 还是以 飞机发动机的为例 现在假如你有了一些 带标签数据 也就是有异常的飞机引擎的样本 这批制造的飞机发动机是有问题的 可能有瑕疵 或者别的什么问题  同时我们还有 一些无异常的样本 也就是一些 完全没问题的样本 我用 y=0 来表示那些 完全正常 没有问题的样本 用 y=1 来代表那些异常样本 

那么异常检测算法的推导和评价方法 如下所示 

我们先考虑 训练样本 交叉验证和测试集等下考虑 对于训练集 我们还是看成无标签的 

训练集 所以这些就是 所有正常的 或者说无异常样本的集合 

通常来讲 我们把这些都看成无异常的 但可能有一些异常的 也被分到你的训练集里 这也没关系 接下来我们要 定义交叉验证集 和测试集 通过这两个集合我们将得到异常检测算法 具体来说 对交叉验证集和测试集 我们将假设 我们的交叉验证集 和测试集中 有一些样本 这些样本都是异常的 所以比如测试集 里面的样本就是 带标签y=1的 这表示有异常的飞机引擎 

这是一个具体的例子 

假如说 这是我们总的数据 我们有10000制造的引擎 作为样本 就我们所知 这些样本 都是正常没有问题的飞机引擎 同样地 如果有一小部分 有问题的引擎 也被混入了这10000个样本 别担心 没有关系 我们假设 这10000个样本中 大多数都是好的 没有问题的引擎 而且实际上 从过去的经验来看 无论是制造了多少年 引擎的工厂 我们都会得到这些数据 都会得到大概20个 有问题的引擎 对于异常检测的典型应用来说 异常样本的个数 

也就是y=1的样本 基本上很多都是20到50个 通常这个范围 对y=1的样本数量 还是很常见的 并且通常我们的 正常样本的数量要大得多 

有了这组数据 

把数据分为训练集 交叉验证集和测试集 一种典型的分法如下 

我们把这10000个正常的引擎 放6000个到 无标签的训练集中 我叫它“无标签训练集” 但其实所有这些样本 实际上都对应 y=0的情况 至少据我们所知是这样 所以 我们要用它们 来拟合p(x) 也就是是我们用这6000个引擎 来拟合p(x) 也就是p 括号 x1 参数是μ1  σ1的平方 一直到p(xn; μn, σn^2) 参数是μn σn的平方 

因此我们就是要用这 6000个样本 来估计参数  μ1, σ1 一直到  μn, σn 这就是训练集中的好的样本 或者说大多数好的样本 

然后 我们取一些 好的飞机引擎样本 放一些到交叉验证集 再放一些到 测试集中 正好6000加2000加2000 这10000个好的样本 就这样进行分割了 同时 我们还有20个 异常的发动机样本 同样也把它们进行一个分割  放10个到验证集中 剩下10个 放入测试集中 在下一张幻灯片中 我们将看到如何用 这些分好的数据 来推导异常检测的算法 

好的 刚才我介绍的这些内容 可能是一种 比较推荐的方法来划分带标签和无标签的数据 来划分好的和坏的飞机引擎样本 我们使用了 6:2:2的比例 来分配好的引擎样本 而坏的引擎样本 我们只把它们放到 交叉验证集和测试集中 在下一页中我们将讲解这样分的理由 

顺便说一下 如果你看到别人应用 异常检测的算法时 有时候也可能会有不同的分配方法 另一种分配数据的方法是这样的 其实我真的不推荐这么分 但就有人喜欢这么分 也就是把10000个好的引擎分出6000个 放到训练集中 然后把剩下的4000个样本 既用作交叉验证集 

也用作测试集 通常来说我们要交叉验证集 和测试集当作是 完全互不相同的 两个数据组 

但就像我说的 在异常检测中 有时候你会发现有些人 会使用相同的 一部分好的引擎样本 用作交叉验证集 也用作测试集 并且有时候你还会发现 他们会把同样的一些异常样本 

放入交叉验证集合测试集 总之 所有这样考虑的 都不是一个好的尝试 非常不推荐 

把交叉验证集 和测试集数据 混在一起共用 确实不是一个比较好的机器学习惯例 但这种情况还不少见 

话说回来 给出之前分好的 训练集、交叉验证集和测试集 异常检测算法的 推导和评估方法如下 

首先 我们使用训练样本 来拟合模型p(x) 也就是说 我们用所有这些高斯函数 来拟合m个无标签的飞机引擎样本 虽然这里我称它们为 无标签的样本 但实际上是我们假设的 都是正常的飞机引擎 

然后假定你的 异常检测算法作出了预测 所以 给出交叉验证集 或者测试集 给出某个测试样本x 假设这个算法对 p(x)<ε 的情况作出的 预测为 y=1 而p(x)≥ε时 算法作出的预测为 y=0 

也就是说 给出x的值 预测出y的值 y=1对应 有异常的样本 y=0对应正常样本 所以给定训练集、交叉验证集和测试集  你应该如何推导算法呢？ 或者更具体来说 怎样评估一个异常检测算法呢？ 为了推导算法 我们的第一步是 取出所有的无标签的训练样本 拟合出模型p(x) 虽然我说的是 无标签的训练集 但实际上这些样本 我们已经假设它们 大多数都是正常的飞机引擎 是没有异常的 然后要用这些训练集 拟合出模型p(x) 也就是用所有这些 高斯模型拟合出参数 

接下来 对交叉验证集 和测试集 我们要让异常检测算法 来对y的值 作出一个预测 所以 假如对我的每一个 测试样本 我们有 

(x(i)test, y(i)test) 其中y=1或0 对应于这个样本是否是异常的 

因此 给定测试集中的输入x 我的异常检测算法 将作出预测 当p(x)小于ε时 预测y=1 所以 在概率值很小的时候 预测样本是异常的 如果p(x)的值大于或等于ε时 算法将预测y=0 也就是说如果概率p(x)比较大的时候 预测该样本为正常样本 

所以现在 我们可以把 异常检测算法想成是 对交叉验证集 和测试集中的y 进行一个预测 这样多多少少让人感到 和监督学习有点类似 不是吗？ 我们有带标签的测试集 而我们的算法就是 对这些标签作出预测 所以我们可以通过 对标签预测正确的次数来进行评价 

当然 这些标签会比较偏斜 因为y=0 也就是正常的样本 肯定是比出现 y=1 也就是异常样本 的情况更多 

这跟我们在监督学习中 用到的评价度量 方法非常接近 

那么用什么评价度量好呢？ 因为数据是非常偏斜的 因为y=0是 更加常见的 因此分类准确度不是一个好的度量法 我们之前的视频中也讲过 

如果你有一个 比较偏斜的数据集 那么总是预测y=0 它的分类准确度自然会很高 

取而代之的  我们应该算出 真阳性、假阳性、 假阴性和真阴性的比率 来作为评价度量值 我们也可以算出查准率和召回率 或者算出 F1-积分 通过一个很简单的数字 来总结出查准和召回的大小 通过这些方法 你就可以评价你的异常检测算法 在交叉验证和测试集样本中的表现 

最后一点 之前在 异常检测算法中 我们有一个参数ε对吧？ 这个ε是我们用来决定 什么时候把一个样本当作是 异常样本的一个阈值 

所以 如果你有 一组交叉验证集样本 一种选择参数ε的方法 就是你可以试一试 多个不同的 ε的取值 然后选出一个 使得F1-积分的值最大的那个ε 也就是在交叉验证集中表现最好的 

更一般来说 我们使用训练集、测试集 和交叉验证集的方法是 

当我们需要作出决定时 比如要包括哪些特征 或者说要确定参数ε取多大合适 我们就可以 不断地用交叉验证集 来评价这个算法 然后决定我们应该 用哪些特征 怎样选择ε 所以 就是在交叉验证集中 评价算法 然后我们选出一组特征 或者当我们找到了 能符合我们要求的ε的值后 我们就能用最终的模型 来评价这个算法 或者说 用测试集 来最终评价算法的表现 

在这段视频中 我们介绍了 如何评价一个异常检测算法 同样地 在能够评价算法之后 通过一个简单的的 数值的评价方法 用一个简单的F1-积分 这样你就能更有效率地 在开发异常检测系统时 更有效率地利用好你的时间 把时间用在刀刃上 我们能够作出决定 确定应该如何选取ε 应该包括哪些特征等等 在这段视频中 刚开始我们用了一组 带标签的数据 目的是为了评价异常检测算法 这让我们感觉到 跟监督学习很相像 

在下一节视频中 我们将更深入地谈到这个问题 具体来说 我们将谈到 应该如何使用异常检测算法  以及什么时候我们应该用监督学习  这两种算法到底有什么区别 【教育无边界字幕组】翻译：所罗门捷列夫 校对：竹二个 审核：小白_远游 






## 15.5、 Anomaly Detection vs. Supervised Learning(异常检测 vs 监督学习)


在上一段视频中 我们谈到 如何评价一个 异常检测算法 我们先是用了一些 带标签的数据 以及一些我们知道是异常 或者正常的样本 用 y=1 或 y=0 来表示 

这就引出了这样一个问题： 我们有了这些带标签的数据 我们有了一些样本 其中一些我们知道是异常的 另外一些是正常的 那我们为什么我们不 直接用监督学习的方法呢？ 为什么不直接用 逻辑回归或者 神经网络的方法 来直接学习这些带标签的数据 从而给出预测 y=1 或 y=0 呢？ 在这段视频中 我就将跟你分享一些 可供参考的方法 关于什么时候应该用 异常检测算法 什么时候用监督学习算法 是更有成效的 

这张幻灯片展示的就是 什么时候应该用异常检测 什么时候用监督学习更加有效 两种情况的一个比较 

如果你的学习问题 正样本的数量很小 别忘了 样本 y=1 表示的是 异常的样本 那么你也许应该考虑使用异常检测算法 

因此 假如有0到20 甚至到50组正样本 通常50个也是很典型的 如果我们有这么小的一组 正样本的话 我们可以把这些正样本 存为交叉验证集 和测试集 相反地 异常检测算法的典型设置 一般应该有一组 比较大量的负样本 也就是正常样本 比如正常的飞机引擎样本 

这样我们就可以 用这组大量的负样本 

来拟合 p(x) 的模型 所以 在许多异常检测应用中 有一种观点就是 如果你有很少的正样本 但有大量的负样本 在对 p(x) 进行估计 并且拟合那些高斯参数的过程中 

我们只需要负样本 因此如果你有很多负样本的话 我们依然可以很好地拟合 p(x) 

反过来 对监督学习 一般来讲 我们的正负样本数量 都应该比较大 

因此 这是一种 可以从你要解决的问题中看出 你应该使用异常检测 还是监督学习算法的方法 

人们对异常检测算法还有另一种认识 对异常检测算法 

通常会有很多种不同的 异常的种类 比如飞机引擎的例子 你知道 引起飞机引擎不工作的原因有很多 对吧？很多部件坏了都可能导致引擎故障 

因此 如果是这样的话 并且如果你只有很少的 一组正样本 那么一个学习算法 要从你这么少的正样本中 学习出这个异常 是比较困难的 具体来说 未来的异常 可能跟你已经见过的完全不同 所以 可能在你的 正样本的集合里 你可能已经有了5种 或者10种 20种 不同的引擎故障的原因 但可能明天 你就需要检测 一种全新的集合 一种全新的异常种类 一种全新的 你从来都没见过的 引擎故障原因 如果是这样的话 那么这更加说明 你应该对负样本 进行建模 建立这个 高斯模型 p(x) 而不是很费力地 对正样本进行建模 因为你知道 (即便你建了模型) 明天你也许就会遇到 你完全没有见过的异常类型 相对而言 在其他一些问题中 你拥有足够多的正样本 你的算法能够感觉到正样本是什么样的 具体来说 如果你认为未来的正样本 跟训练集中的 很相似的话 那么在这样的条件下 用监督学习算法似乎更加合理 既使用大量的 正样本 也使用 大量的负样本 并且尝试对正负样本进行分类 

希望这样讲 你能够明白 当遇到具体的问题时 应该使用异常检测算法 还是监督学习算法 

关键的区别就是 在异常检测算法中 我们只有一小撮 正样本 因此学习算法不可能 从这些正样本中学出太多东西 因此取而代之的是 我们使用一组大量的 负样本 这样样本就能学到更多 或者说能从大量的负样本 比如大量的正常引擎样本中 学出 p(x) 模型 另外 我们预留一小部分 正样本来评价我们的算法 既用于交叉验证集 也用于测试集 

另外再额外说一点 关于这些不同类型的 异常情况 在前面的一些视频中 我们提到了垃圾邮件的例子 在那些例子中 垃圾邮件的类型其实也有很多种 有的是想卖东西给你 有的是想钓出你的密码 这种就叫钓鱼邮件 还有其他一些类型的垃圾邮件 但对于垃圾邮件的问题 我们通常有足够多的 垃圾邮件的样本 我们能得到绝大多数不同类型的 垃圾邮件 因为我们有大量的 垃圾邮件样本的集合 因此这也是为什么 我们通常把垃圾邮件问题看作是 监督学习问题的原因 虽然垃圾邮件的种类 通常有太多太多 

因此 我们可以看看 一些异常检测的应用 和监督学习应用的比较 我们不难发现 对于欺诈检测(fraud detection) 如果你掌握了许多种 不同类型的 诈骗方法 并且相对较小的训练集 很少的一些你网站上 出现的欺诈用户 那我会使用异常检测算法 

当然 我要声明一点 如果你是一个大型在线零售商 并且你掌握了 大量的 想要在你的网站上 实施诈骗犯罪的人 也就是说 你有很多 y=1 的样本 那么有时候 欺诈检测的方法也可能会 偏向于使用监督学习算法 但是 如果你 并没有看到许多 在你网站上 进行异常行为的用户样本 那么欺诈检测 通常还是被当做是 一个异常检测算法 而不是一个监督学习算法 

还有另外一些例子 我们已经谈到了生产中的应用 我们期待看到更多的正常样本 少出现一些异常情况 但对一些生产过程来说 如果你进行大量的生产作业 并且发现了 比较多的坏的样本 那么这个问题同样也可能 转向一个监督学习问题 但如果你并没有看到 太多的不正常样本 那么还是把它当做异常检测问题来处理 

数据中心的监控机器 同样地 前面那些讨论 也适用于这种情况 

相对而言 垃圾邮件分类、天气预报 以及癌症诊断的问题 如果你拥有相同数量 的正负样本 或者说既有大量的 正样本 也有大量的 负样本 那么我们还是 倾向于把这些问题当做监督学习 

希望这节课能让你 明白一个学习问题的 什么样的特征 能让你把这个问题 当做是一个异常检测 或者是一个监督学习的 

问题 另外对于很多技术公司 可能会遇到的一些问题 通常来说 正样本的数量很少 甚至有时候是0 也就是说 出现了太多没见过的 不同的异常类型 那么对于这些问题 通常应该使用的算法就是 异常检测算法

## 15.6、 Choosing What Features to Use(选择要使用的功能)


在此之前 你已经学习了 异常检测算法 并且 我们也讨论了如何 评估一个异常检测算法 事实上 当你应用异常检测时 对它的效率 影响最大的 因素之一是 你使用什么特征变量 你选择什么特征变量 来输入异常检测算法 那么 在本视频中 我将要做的事情就是 给你们一些建议 关于如何设计或选择 异常检测算法的 特征变量 

在我们的异常检测算法中 我们做的事情之一就是 使用这种正态(高斯)分布来对特征向量建模 就是有 xi 服从正态分布 期望为μi 方差为 σi 平方 那么 我常做的一件事 就是画出这些数据 

或者用直方图表示数据 以确保 这些数据在 应用我的异常检测算法前 看起来像高斯分布 当然即使你的数据并不是高斯分布 它也基本上可以良好地运行 它也基本上可以良好地运行 如果你的数据 看起来不像正态分布 算法也常常可以正常运行 但是具体而言 我将数据画成这样 如果它的柱状图看起来 像这样 另外说一下 画柱状图的方法是 使用 hist 命令 就是 Octave 里面的 hist 命令 但看起来好像 这个图形近似像一个高斯分布 所以如果我的特征变量是这样的 那么我可以很高兴地把它们送入我的学习算法了 但如果我画出来的 直方图是这样的话 好吧 那么这就看起来完全不像钟形曲线 这个分布很不对称 它的峰值非常偏向一边 

如果我的数据是这样的话 通常我要做的事情 是对数据进行一些不同的转换 来确保这些数据 看起来更像高斯分布 虽然通常来说你不这么做 算法也会运行地很好 但如果你使用一些转换方法 使你的数据更像高斯分布的话 你的算法会工作得更好 

所以 如果给我这样的数据集 我通常要做的是 进行一个求对数的转换 如果我这样做的话 重新把直方图画出来 对于这个具体的例子 我就会得到 像这样的一个直方图 这样就看起来更像高斯分布了 对吧？ 这看起来就更像典型的钟形曲线 这样我就能拟合出期望和方差参数了 

所以这里我说的 进行一个取对数的转换 意思是这样的 如果我有一个特征变量 比如 x1 直方图是这样的 那么我就用 x1 的对数 log(x1) 来替换掉 x1 所以 经过替换 这就是我的新 x1 我把它的直方图画在右边 这看起来更像高斯分布了 

除了取对数变换之外 还有别的一些方法也可以用 假如这是另一个特征 x2 现在我用 log(x2 + 1) 来取代 或者更一般地 我可以在 x2 后面加上 

某个常数 c  然后求对数来取代 x2 我会调整这个常数 c 的值 使得这个分布看起来尽可能地像高斯分布 

或者对于另一个特征 x3 也许我可以用 

它的平方根来取代 x3 的平方根也就是 x3 的二分之一次方 对吧？ 

而这个 二分之一  又是一个可以由我来确定的参数 所以 或许对另一个特征 x4 我可以用 x4 的另一个幂次方 来取代 x4 比如说可以用 三分之一次幂 所有这些 所有这些参数 这个指数参数 或者这个参数 c 所有这些参数你都可以进行调整 目的只有一个 就是让数据看起来更像高斯分布 

下面我给你演示一下 如何对这些参数进行调整 来让我的数据看起来更像高斯分布 这里我已经在 Octave 中 加载了一系列特征 x 这里我加载了1000个样本 这里我加载了1000个样本 所以让我们来画出数据的直方图 

使用 hist(x) 命令 这就是我的直方图了 

默认情况下 直方图有十个柱 可以重新把样条设置地更好一点 我们输入 hist(x, 50) 这样就画出了50个柱 这样看起来好多了 但现在看起来还不够"高斯" 所以下面我们来调整一下参数 首先试试 x 的0.5次方 也就是说 我们对数据取平方根 然后画出直方图 

好了 现在看起来 有那么一点像高斯分布了 但还是不够好 我们再调整一下 我们来看 

把0.5减小到0.2试试 又更像高斯分布了一点 

我们再减小一点 试试0.1 

耶！好极了 所以我可以使用0.1 我们再试试更小的 0.05 然后 你看 这样看起来更像高斯分布了 因此 我们可以定义一个 新的特征变量 xNew 等于 x 的0.05次方 现在我的新特征变量 xNew 比原来的特征变量 看起来更具像高斯分布 因此我就可以用这个新的 特征变量来输入到我的 异常检测算法中 当然 实现这一功能的方法不唯一 你也可以用 hist(log(x), 50) 这是另一种你可以选择的转换方法 这同样会让你的数据看起来更像高斯分布 所以 我们也可以 让 xNew 等于 log(x) 这是另一种可以选用的 很好的特征变量 

我们来总结一下 如果你画出数据的直方图 并且发现图形看起来 非常不像正态分布 那么应该进行一些 不同的转换 就像这些 通过这些方法 来让你的数据看起来 更具有高斯分布的特点 然后你再把数据输入到学习算法 虽然说 你不这么做也可以 但我通常还是会进行这一步 下面我想讲第二个问题 那就是你如何得到 异常检测算法的特征变量 

我通常用的办法是 通过一个误差分析步骤 

我的意思是 这跟我们之前 学习监督学习算法时的 误差分析步骤是类似的 也就是说 我们先完整地训练出 一个学习算法 然后在一组交叉验证集上运行算法 然后找出那些预测出错的样本 然后再看看 我们能否找到一些其他的特征变量 来帮助学习算法 让它在那些交叉验证时 判断出错的样本中表现更好 

让我们来用一个例子 详细解释一下刚才说的这一过程 在异常检测中 我们希望 p(x) 的值 对正常样本来说是比较大的 而对异常样本来说 值是很小的 

因此 一个很常见的问题是 p(x) 是具有可比性的 也许正常样本和异常样本的值都很大 

我们来看一个具体点的例子 假如说这是我的无标签数据 那么 我只有一个特征变量 x1 我要用一个高斯分布来拟合它 

假如我的数据拟合出的高斯分布是这样的 

现在假如我有一个异常样本 假如我的异常样本中 x 的取值为2.5 因此 我画出我的异常样本 你不难发现 它看起来就像被淹没在 一堆正常样本中似的 

我用绿色画出来的 这个异常样本 它的概率值很大 是蓝色曲线的高度 而我们的算法 没能把这个样本判断为异常 

现在如果说这代表 飞机引擎的制造或者别的什么 那么我会做的是 我会看看我的训练样本 然后看看到底是 哪一个具体的飞机引擎出错了 看看通过这个样本 能不能启发我 想出一个新的特征 x2 来帮助算法区别出 不好的样本 和我剩下的正确的样本 也就是那些红色的叉叉 

或者说正常的飞机引擎样本 

如果我这样做的话 我们的期望是 创建一个新的特征 x2 使得 当我重新画数据时 如果我用训练集中的 所有正常样本 我应该就会发现 所有的训练样本都是这里的红叉了 我们也希望能看到 对于异常样本 这个新特征变量 x2 的值会看起来是异常的 因此对于我这里的绿色的样本 这是异常的样本 对吧 我的 x1 值仍然是2.5  那么我的 x2 很有可能 是一个比较大的值 比如这里的3.5 

或者一个非常小的值 

现在如果我再来给数据建模 我会发现 我的异常检测算法 会在中间区域 给出一个较高的概率 然后越到外层越小 到了那个绿色的样本 我的异常检测算法 会给出非常小的概率值 

会给出非常小的概率值 所以这个过程 实际上就是 

看看哪里出了错 看看那些 算法没能正确标记的异常点 看看你能不能得到启发来创造新的特征变量 所以也就是说 找一找飞机引擎中的不寻常的问题 然后来建立一些新特征变量 有了这些新的特征变量 应该就能更容易 从正常样本中区别出异常来 这就是误差分析的过程 这就是误差分析的过程 

以及如何为异常检查算法 建立新的特征变量 最后 我想与你分享一些 我平时在为异常检查算法 选择特征变量时的一些思考 

通常来说 我想到的选择特征变量的方法是 我会选那些取值 既不会特别特别大 也不会特别特别小的 那些特征变量  比如说 

我们还是用这个数据中心中 监控计算机的例子 比如 在一个数据中心 你有很多台电脑  也许上千 或者上万台 我们想要知道的是 是不是有哪一台机器 运作不正常了 这里给出了几种可选的特征变量 包括占用内存 磁盘每秒访问次数 CPU负载 网络流量 

现在假如说 我怀疑某个出错的情况 假如说 我认为 在我的数据中 我的CPU负载和网络流量 应该互为线性关系 可能我运行了一组 网络服务器 如果其中一个服务器 在对许多用户服务 那么我的CPU负载和网络流量都很大 

现在假如说 我怀疑其中一个出错的情形 是我的计算机在执行一个任务时 进入了一个死循环 因此被卡住了 意思就是说 假如我感觉 我的其中一台机器 或者说其中一台服务器的代码 执行到一个死循环卡住了 因此CPU负载升高 但网络流量没有升高 因为只是CPU执行了 较多的工作 所以负载较大 卡在了死循环里 在这种情况下 要检测出异常 我可以新建一个特征 x5 x5 等于 CPU负载 

除以网络流量 

因此 x5 的值 将会变得不寻常地大 如果某一台机器 具有较大的CPU负载 但网络流量正常的话 因此 这将成为一个 很好的特征 能帮助你 检测出某种类型的异常情况 你就会看到有个名为 mycode.R 的文件 用同样的方法得到更多其他的特征 比如说我可以 建立一个特征 x6 等于 CPU负载的平方除以网络流量 

这就像是特征 x5 的一个变体 实际上它捕捉的异常 仍然是你的机器 是否具有一个比较高的 CPU 负载 但没有一个 同样很大的网络流量 

通过这样的方法 建立新的特征变量 

你就可以通过不同特征变量的组合 

捕捉到对应的不寻常现象 

在这段视频中 我们介绍了如何选择特征 以及对特征进行一些 小小的转换 让数据更像正态分布 然后再把数据输入异常检测算法 同时也介绍了建立特征时 进行的误差分析方法 来捕捉各种异常的可能 希望你通过这些方法 能够了解如何选择好的特征变量 从而帮助你的异常检测算法 捕捉到各种不同的异常情况 


### Multivariate Gaussian Distribution(Optional)
---
## 15.7 Multivariate Gaussian Distribution(多变量高斯分布)

0:00
在这节和下节视频中 我想给你介绍 我们目前为止学习的异常检测算法的 一种可能的延伸 这个延伸使用了 多元高斯分布 (multivariate Gaussian distribution) 它有一些优势 也有一些劣势 它能捕捉到一些之前的算法检测不出来的异常 
0:21
为了理解这个算法 我们先来看看一个例子 
0:25
假设我们的没有标签的数据看起来像这张图一样 我要使用数据中心的监控机的例子 我要使用数据中心的监控机的例子 就是在数据中心监控计算机的例子 所以我的两个特征变量 x1 是 CPU 的负载和 x2 可能是内存使用量 
0:41
所以如果我 把这两个特征变量 x1 和 x2 当做高斯分布来建模 这个是特征变量 x1 绘制的图 这个是特征变量 x2 的图 如果我能找到一个 它所符合的高斯分布 我得到的高斯分布可能是这样的 所以这是 p(x1; 它的参数 µ1 它的参数 µ1 和 σ1 的平方 ) 然后这是内存使用量 可能我会得到这样的一个高斯分布 这是 p(x2; 参数 µ2 和 σ2 的平方 ) 因此这就是一个 异常检测算法对 x1 和 x2 建模的方法 
1:19
现在假如说 在测试集中 有一个这样的样本 
1:25
在这个绿色叉的位置 它的 x1 的值是 0.4 左右 x2 的值是 1.5 左右 现在 如果你看看 看起来它们大部分 看起来它们大部分 都在这个范围内 所以这个绿色叉 离这里看到的任何数据都很远 看起来它应该被当做 一个异常数据 所以我的 好的样本的数据 看起来 CPU 负载 和内存使用量 是彼此线性增长的关系 所以 如果我有一台机器 CPU 使用量很高 那么你就知道 内存使用量也会很高 但是这个绿色样本 看起来 CPU 负载很低 但是内存使用量很高 我以前从没在 训练集中见过这样的 看起来它应该是异常的 
2:13
但是我们来看一下异常检测算法会怎么做 对于 CPU 负载 这个绿色叉差不多在 0.5 这里 有相当高的可能性 它离看到的其它样本不远 它离看到的其它样本不远 相对的 对于内存使用量 这个点是 0.5 而对于内存使用量 它是差不多 1.5 在那里 它在这个高斯分布的尾部 它在这个高斯分布的尾部 但是这里的值和这里的值 与看到的其他那些样本 没有太大差别 所以 p(x1) 会很高 所以 p(x1) 会很高 
2:45
会比较高 p(x2) 也会比较高 我的意思是 如果你看这幅图 这里这个点 看起来它并没那么差 然后如果你看这幅图 这个叉 看起来也不那么差 我的意思是 有的样本 内存使用量更高 或者 CPU 使用量更低 所以这个点看起来不是很异常 
3:05
所以 一个异常检测算法 不会将这个点标记为异常 可以看出来 我们的异常检测算法 不能察觉到 不能察觉到 这个蓝色椭圆所表示的 好样本概率高的范围 它所做的是 这部分样本是高概率的 外面一些的圈里面的样本 
3:26
是好样本的概率低一些 而这里的样本概率更低 然后事情就变成了 那里的绿色叉 是好样本的概率挺高 
3:34
具体来说 它倾向于认为所有在这区域中的 在我画的这个圈上的样本 都具有相同的概率 它并不能意识到 这边的其实比那边的 概率要低得多 
3:55
所以 为了解决这个问题 我们要开发一种 改良版的异常检测算法 改良版的异常检测算法 要用到一种 叫做多元高斯分布或者多元正态分布的东西 
4:07
所以这是我们要做的 我们有特征 x 它是 n 维实数 我们不要把 p(x1) p(x2) 分开 而要建立一个 p(x) 整体的模型 就是一次性建立 p(x) 的模型 
4:20
多元高斯分布的参数 包括向量 µ 和一个 n×n 矩阵 Σ Σ 被称为协方差矩阵 
4:29
它类似于我们之前 在学习 PCA 也就是主成分分析的时候 也就是主成分分析的时候 所见到的协方差矩阵 
4:37
我们来试着完成这个 让我来写出 
4:40
多元高斯分布的公式 我们说 x 的概率 确定它的参数是 我的参数 µ 和 Σ 我的参数 µ 和 Σ x 的概率等于 再说一次 完全没有必要去记这个公式 
4:56
因为你可以在 任何需要用它的时候找到它 但是 x 的概率 看起来是这样的 
5:03
转置 Σ 的逆 x-µ 
5:07
这边这个东西 
5:10
Σ 的绝对值 当我们写这个符号的时候 这个东西叫做 Σ 的行列式 (determinant) 它是一个矩阵的数学函数 你不需要知道 你不需要知道 矩阵的行列式是什么 你真的需要知道的 就是可以在 Octave 里 使用 Octave 命令 det(Sigma) 来计算它 
5:33
det(Sigma) 来计算它 好 再确认一次 在这个表达式中 这些 Σ 是 n×n 矩阵 这不是一个求和符号 这个 Σ 是一个 n×n 矩阵 
5:46
所以那就是 p(x) 的公式 但是更有趣 或者说更重要的是 
5:53
p(x) 到底是什么样子 我们来看一些 多元高斯分布的例子 
6:02
我们来看一个二维的例子 我们来看一个二维的例子 如果我有 n 等于 2 两个特征 x1 和 x2 
6:09
如果说我让 µ 等于 0 如果说我让 µ 等于 0 让 Σ 等于这个矩阵 让对角线上的值等于 1 非对角线上的值等于 0 这个矩阵有时会被叫做单位矩阵 (identity matrix) 
6:21
在这个情况下 p(x) 看起来会是这样 我在这个图里展示的是 我在这个图里展示的是 对于一个特定的 x1 的值 和一个特定的 x2 的值 这个面的高度 这个面的高度 就是 p(x) 的值 所以在这个参数设定下 
6:40
p(x) 在 x1 和 x2 都等于 0 时最高 那就是高斯分布的峰值 
6:46
然后这个概率 这个二元高斯分布 随着这个二维钟形的面衰减 
6:55
下面这个图和上面是一样的 但它是用等高线 或者说不同颜色画的图 所以中间这里这个 很强烈的暗红色 对应的是最高值 然后这个值降低 黄色表示低一点儿的值 青色表示更低一些的值 这里的深蓝色 表示的是最低的值 所以这个其实是同一张图 就是采用俯视的角度 并且使用了颜色 
7:21
所以 从这个分布 
7:23
你可以看出来 大部分概率都在 0 0 附近 然后 随着从 0 0 这个点往外延伸 x1 和 x2 的概率下降 
7:36
现在我们来试试 改变一些参数 然后看看会发生什么 我们来改变一下 Σ 假如说缩小一下 Σ Σ 是一个协方差矩阵 所以它衡量的是方差 所以它衡量的是方差 或者说特征变量 x1 和 x2 的变化量 所以如果缩小 Σ 那么你的得到的是 那么你的得到的是 这个鼓包的宽度会减小 
7:57
高度会增加一点 因为在这个面以下的 区域等于 1 所以这个面以下的 体积的积分等于 1 因为概率分布的积分 必须等于一 但是 如果你缩小方差 
8:12
相当于缩小 Σ 的平方 相当于缩小 Σ 的平方 你会得到一个窄一些 高一些的分布 在这儿你也看到 这些同心椭圆也缩小了一些 而相对的 如果你 
8:29
增加 Σ 对角线上的值到 2 2 所以它现在是单位矩阵的二倍 那么最后你会得到 一个更宽更扁的高斯分布 所以这个的宽度会更宽 虽然很难看出来 但这还是一个钟形的鼓包 它只是扁平了很多 它变得更宽了 所以 x1 和 x2 的方差 或者变化量变大了 
8:50
下面再举几个例子 现在我们试一下 一次改变 Σ 的一个元素 假如说我把 Σ 改为这里是 0.6 那里是 1 
9:01
它所做事情的是 减小第一个特征变量 x1 的方差 
9:05
减小第一个特征变量 x1 的方差 同时保持第二个特征变量 x2 的方差不变 在这个参数设置下 就可以给这样的东西建模 x1 有小一些的方差 而 x2 有大一些的方差 然而如果我这样做 把这个矩阵设置为 2 1 把这个矩阵设置为 2 1 那么你也可以 建立这样的模型 
9:28
x1 的变化范围比较大 x1 的变化范围比较大 而 x2 的变化范围则窄一些 它也被反映到这张图上了 它也被反映到这张图上了 这个分布随着 x1 远离 0 这个分布随着 x1 远离 0 下降得更缓慢 而随着 x2 远离 0 下降得非常快 
9:49
类似地 如果我们改变 矩阵的这个元素 那么会类似于上一页 
9:57
除了在这儿 我们说 x2 的变化区间非常小 我们说 x2 的变化区间非常小 我们说 x2 的变化区间非常小 所以在这里 如果这个是 0.6 我们发现现在 
10:09
x2 的变化区间 比原来的例子要小很多 
10:14
然而如果我要让 Σ 等于 2 然而如果我要让 Σ 等于 2 这就是说让 x2 有大一些的变化区间 
10:22
现在 多元高斯分布的 现在 多元高斯分布的 一个很棒的事情是 你可以用它给数据的 相关性建立模型 我们可以用它 来给 x1 和 x2  高度相关的情况 建立模型 所以具体来说 如果你改变协方差矩阵 非对角线上的元素 你会得到一种不同的高斯分布 
10:46
所以当我将非对角线的元素 所以当我将非对角线的元素 从 0.5 增加到 0.8 时 我会得到一个 更加窄和高的 沿着 x=y 这条线的分布 然后这个等高线图告诉我们 x 和 y 看起来是 一起增加的 概率高的地方是这样的 概率高的地方是这样的 要么 x1 很大  x2 也很大 或者 x1 很小 x2 也很小 或者是这两者之间 然后随着这个值 0.8 增大 你会得到这样一个高斯分布 差不多全部的概率 都在一个很窄的范围内 
11:24
也就是 x 几乎等于 y 它是一个非常高 而且非常薄的分布 几乎完全在 x 非常接近于 y 的这样一个 
11:33
几乎完全在 x 非常接近于 y 的这样一个 非常窄的范围内 这是当我们把这些元素 设置为正数时的情况 相对地 如果我们 将它们设置为负数 随着我把它从 -0.5 减小到 -0.8 那么我得到的模型是 大部分的概率都在 x1 和 x2 负相关的这样一个区域内 x1 和 x2 负相关的这样一个区域内 那么大部分的概率 几乎都落在 x1 和 -x2  差不多相等的区间内 而不是 x1 等于 x2 的区间 而不是 x1 等于 x2 的区间 所以这个捕捉到了 x1 和 x2 的负相关性 
12:10
x1 和 x2 的负相关性 因此这就是一个 能让你体会到 多元高斯分布所能展现的 不同的分布 
12:18
到目前为止 我一直在改变协方差矩阵 Σ 你还可以做的事情是 改变平均值参数 µ 改变平均值参数 µ 我们的 µ 本来是等于 0 0 的 我们的 µ 本来是等于 0 0 的 所以分布才会集中在 x1=0 x2=0 这个点周围 所以这个分布的峰值在这里 所以这个分布的峰值在这里 而如果我们改变 µ 的值 它就会改变 这个分布的峰值 所以如果 µ 等于 0 0.5 这个峰值就在 x1=0 x2=0.5 这里 所以这个分布的 峰值或者说中心 就会被移动 
12:56
如果 µ 等于 1.5 -0.5 那么还是同样地 
13:01
现在分布的峰值 就会被移动到 另一个地方 这个新地方就对应 x1=1.5 x2=-0.5 这个点 所以改变参数 µ 就是在移动 这整个分布的中心 所以 希望这些 不同的图片 能够帮助你了解一下 多元高斯分布 所能描述的概率分布是什么样的 它最重要的优势 就是它可以让你 能够描述当两个特征变量之间 可能存在正相关 或者是负相关关系的情况 
13:37
在接下来的视频中 我们要把这个多元高斯分布 应用到异常检测中 【教育无边界字幕组】翻译: 竹二个 校对/审核: 所罗门捷列夫 





## 15.8、 Anomaly Detection using the Multivariate Gaussian Distribution(使用多变量高斯分布的异常检测)


在上一节视频中 我们谈到了多元高斯分布 
0:04
而且也看到了一些例子 通过改变参数 µ 和 Σ 来给不同的概率分布建模 在这节视频中 我们来使用那些想法 用它们来开发另一种异常检测算法 
0:19
再回顾一下多元高斯分布 或者叫多元正态分布 有两个参数 µ 和 Σ µ 是一个 n 维向量 协方差矩阵 Σ 
0:32
是一个 n 乘 n 矩阵 是一个 n 乘 n 矩阵 
0:37
这个式子是 x 的概率分布 这个式子是 x 的概率分布 参数是 µ 和 Σ 随着你改变 µ 和 Σ 随着你改变 µ 和 Σ 你可以得到一系列 不同的概率分布 这里有三个例子 我们在上节视频中见过 
0:51
接下来 让我们谈一下 参数拟合问题 或者说参数估计问题 和往常一样 问题是 如果我有一组样本 从 x(1) 到 x(m) 这里的每一个样本 都是 n 维向量 而且我认为它们服从多元高斯分布 
1:09
我应该怎么估计参数 µ 和 Σ 呢？ 估计它们的 标准公式是这样的 µ 等于你的 训练样本的平均值 
1:21
让 Σ 等于这个式子 这个 Σ 实际上 就是我们在使用 PCA 就是我们在使用 PCA 或者说主成分分析法时 所写的 Σ 的式子 
1:31
然后你把数据代入到 这两个式子中 就得到了估计值参数µ 和估计值参数Σ 
1:41
所以 当给定数据集时 就这样来估计 µ 和 Σ  我们来使用这个方法 把它用到 异常检测算法中 那么我怎么把这些放在一起 那么我怎么把这些放在一起 来开发一个异常检测算法呢？ 我们这样做 首先 用我们的训练集 来拟合模型 p(x) 来拟合模型 p(x) 你知道 就是要让 µ 和 Σ 等于 
2:03
上一页所描述的这样 
2:07
然后 等你拿到 一个新样本 x 如果你拿到一个测试样本 
2:12
我们还用之前的例子 拿到的新样本在这里 那是我的测试样本 
2:18
拿到一个新样本 x 我们要做的就是 用这个多元高斯分布的公式 来计算 p(x) 
2:27
然后 如果 p(x) 非常小 那我们就把它标记为一个异常点 那我们就把它标记为一个异常点 而如果 p(x) 大于那个参数 ε 那我们就不把它标记为异常点 所以说 如果我们要用一个多元高斯分布来拟合这个数据集 指的是这些红色叉 不是绿色样本 你会得到一个这样的高斯分布 大部分的概率在中间这个区域 大部分的概率在中间这个区域 这里的概率稍微低一些 这里的概率再稍微低一些 这里的概率再稍微低一些 
2:56
远处这个点的概率非常低 
3:01
所以 当你 在这个样本上用多元高斯分布 它实际上会 正确地把那个样本 标记为一个异常点 
3:16
最后 应该稍微说一下 多元高斯分布模型 多元高斯分布模型 和原来的模型 它们之间的关系 p(x) 原来的模型是 p(x1) 乘以 p(x2) 一直乘到 p(xn) 的积 p(x1) 乘以 p(x2) 一直乘到 p(xn) 的积 p(x1) 乘以 p(x2) 一直乘到 p(xn) 的积 
3:32
事实上 你可以从数学上证明 我不打算在这里进行证明 但是你可以从数学上证明 多元高斯模型 和原来的模型 之间的关系 详细来说就是 事实上原来的模型 对应于一种多元高斯分布 它的等高线 全部都是沿着轴向的 
3:55
所以这三个 全都是你可以用 原来的模型来拟合的 高斯分布的例子 事实上 它对应于 这样的多元高斯分布 这样的椭圆 这样的分布等高线 事实上这个模型 实际上它对应于一种 多元高斯分布的特例 具体来说 这个特例被定义为 
4:24
约束 p(x) 的分布 也就是多元高斯分布 p(x) 也就是多元高斯分布 p(x) 使得它的概率密度函数的等高线 使得它的概率密度函数的等高线 或者说概率分布函数的等高线 是沿着轴向的 所以你可以得到 多元高斯分布 p(x) 看起来是这样 或者是这样 或者是这样 然后你发现 在这3个例子  或者说我所画的这些椭圆中 它们的轴都是沿着 x1 x2 的轴的 
4:54
在其中没有 带有角度的 一组等高线 这个对应于那个 Σ 等于 1 1 0.8 0.8 的例子 就是非对角线上有 非零元素的例子 所以 事实上 可以用数学证明 这个模型实际上 和多元高斯分布一样 只是有一个约束 这个约束是 协方差矩阵 Σ 必须满足 非对角线的元素为0 具体来说 协方差矩阵 Σ 也就是这里这个 它等于 σ1 ^2 σ2^2 一直到 σn^2 它等于 σ1 ^2 σ2^2 一直到 σn^2 然后 所有 非对角线上的项 所有这些在矩阵对角线 
5:43
之上或者之下的元素 所有这些全都等于0 
5:47
实际上如果你 把这些 σ σ1^2 σ2^2 把这些 σ σ1^2 σ2^2 一直到 σn^2 把它们代入到这里 把它们代入到 这个协方差矩阵中 那么这两个模型实际上就完全一样了 就是说 这个新模型 
6:06
使用多元高斯分布来看 
6:08
刚好对应于这个旧模型 如果这个协方差矩阵 Σ 在非对角线上的元素 只有0的话 从图上来看 它对应于 
6:20
分布函数的等高线 是沿着轴向的高斯分布 所以你不能给不同特征变量之间的相关性建模 
6:30
这样看来 原来的模型 实际上是这个多元高斯模型的一个特例 
6:38
所以你应该在什么时候用哪个模型呢？ 什么时候该用原来的模型 什么时候该用 多元高斯模型呢？ 
6:52
原来的模型 可能使用得更加频繁 
6:58
而多元高斯模型 则没有那么常用 但是它有能够捕捉 特征变量之间的相关性的优势 
7:10
如果你想捕捉到这样的异常 如果你想捕捉到这样的异常 你有不同的特征变量 比如说特征变量 x1 x2 的值的组合是不正常的 在之前的例子中 我们的异常的例子是 CPU 负载和内存使用量的值的组合是不正常的 
7:30
如果你想用原来的模型 捕捉到这个情况 你需要建立一个新特征变量 你需要建立一个新特征变量 比如说 x3=x1/x2 可能是等于 CPU 负载除以内存使用量 或者别的什么 
7:47
你需要建立一个新特征变量 如果有不正常的变量值组合这种情况 也就是说 x1 和 x2 的取值 的组合是不正常的 虽然 x1 自己 和 x2 自己的值 
7:59
看起来非常的正常 但是如果你愿意花时间 手动建立这样的新特征变量 那么原来的模型可以很好地运行 而相对地 多元高斯模型可以自动捕捉 不同特征变量之间的相关性 但是原来的模型也有一些其他的很重要的优势 其中一个很大的优势就是 
8:28
它的运算量更小 换种说法是 它更适用于 n 的值非常大 就是说特征变量很多的情况 所以即便 n 等于 10,000 
8:39
或者 n 等于 100,000 原来的模型 通常都可以很好地运行 而对于多元高斯模型要注意 例如 我们要计算 矩阵 Σ 的逆矩阵 在这里 Σ 是一个 n 乘 n 的矩阵 
8:56
所以如果要计算的 Σ 是一个 100,000 乘 100,000 的矩阵 那么这个计算量会非常大 所以多元高斯模型 不是非常适合 n 很大的情况 最后 对于原来的模型 事实上 即使你的训练集相对较小 它也能运行得还可以 这是我们用来给 p(x) 建模的 无标签的小训练集 
9:20
当然 这个运行得很好 即使 m 可能是 
9:24
50 或者 100 也工作得很好 而对于多元高斯模型 这个算法的数学性质要求 你的 m 必须大于 n 所以样本的数量要大于特征变量的数量 我们估计参数的方法有个数学性质是 
9:41
如果不满足这个条件 就是说 m 小于或等于 n 那么这个矩阵是不可逆的 是奇异矩阵 如果你不能改变这个的话就不能使用多元高斯模型 
9:54
但是我所使用的典型的经验法则是 我只在当 m 远大于 n 的时候 使用多元高斯模型 
10:04
所以这是一个比较严格的数学要求 但是在实际中 我只有在 m 比 n 大很多的情况下 才使用多元高斯模型 所以如果 m 大于等于十倍的 n m 大于等于十倍的 n 这可能是个合理的经验法则 
10:18
如果它不满足这个 那么多元高斯模型 有很多的参数 对吧 这个协方差矩阵 Σ 是一个 n 乘 n 矩阵 所以它大概有 n 的平方个参数 因为它是个对称矩阵 实际上它有大概 n 平方除以 2 个参数 实际上它有大概 n 平方除以 2 个参数 但这是非常多的参数 所以你需要确保你的 m 比较大 确保你有足够的数据来拟合这些参数 m 大于等于十倍的 n 是一个比较合理的经验法则 它能确保你对协方差矩阵 Σ 的估计比较好 
10:55
所以在实际应用当中 左边这个原来的模型比较常用 如果你觉得 你需要捕捉特征变量之间的相关性 一般人就会手动增加这样的额外特征变量 来捕捉特定的不正常的值的组合 但是在你的训练集很大 或者说 m 很大 n 不太大的情况下 
11:17
那么多元高斯模型 是值得考虑得 或许可以运行得更好 
11:24
还可以帮你省去 为了捕捉不正常的特征值组合 才能捕捉到的异常 
11:31
而手动建立额外特征变量 所花费的时间 
11:37
最后我只想 简单提一个技术上的性质 如果你想拟合 多元高斯模型 如果你发现 协方差矩阵 Σ 是奇异的 或者说你发现 它是不可逆的 一般只有两种情况 第一种是它没有满足 这个 m 大于 n 的条件 第二种情况是 你有冗余特征变量 冗余特征变量的意思是 如果你两个一样的特征变量 不知怎么你不小心把同一个特征变量 复制了两份 那么你的 x1 刚好等于 x2 或者如果你有像这样的冗余数据 
12:12
可能是 x3=x4+x5 好了 如果你有像这样 高度冗余的特征变量 如果 x3=x4+x5 那么 x3 就不含有 任何额外的信息 对吧？ 就只是把另外两个特征变量加起来而已 
12:27
如果你有这样的 冗余特征变量 重复特征变量 或者这样的特征变量 那么 Σ 就会是不可逆的 
12:35
这是调试时候的小知识 这个应该很少发生 所以你可能不会碰到这个问题 你可能不太需要担心这个 但是万一在你实现 多元高斯模型的时候发现 Σ 是不可逆的 
12:48
我会做的首先是 确保 m 比 n 大很多 如果是这样 那么我做的第二件事是 检查冗余特征变量 如果有两个特征变量相等 就删掉其中一个 就删掉其中一个 如果你的冗余数据是 x3=x4+x5 这样的 就删掉容易的特征变量 然后它应该就可以很好地运行了 对你们之中那些 了解线性代数的人 我所说的冗余特征变量 它的正式用语是 线性相关的特征变量 但是在实际中它的意思就是 这些之中的问题导致算法有问题 如果你确保特征变量没有冗余的 应该就能解决 Σ 不可逆的问题 但是再说一次 你遇到这个问题的可能性 非常低 你可以直接应用 多元高斯模型 不需要担心 Σ 不可逆的问题 只要 m 大于等于 n 只要 m 大于等于 n 这就是应用多元高斯分布 的异常检测算法 如果你使用这个方法 你就可以使你的 异常检测算法 自动捕捉不同特征变量之间的 正相关或负相关性 并且在特征值的组合 不正常的时候 将它标记为异常 【教育无边界字幕组】翻译：竹二个 校对/审核：所罗门捷列夫 
Downloads

Lecture Videomp4
Subtitles (Chinese (Simplified))
WebVTT





### Review