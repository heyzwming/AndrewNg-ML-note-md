章节2 单变量线性回归
===

## Model and Cost Function

## 课时6  模型描述   08:10
上一章已经通过卖房价格的模型简单介绍了什么是回归：我们尝试将变量映射到某一个连续函数上。

![6.1]()

这章我们将这个问题简单地量化为**单变量线性回归模型**(Univariate linear regression)来理解它。

我们有一堆数据集，也叫训练集，下图我们来定义一些课程中用到的符号。

首先，我们定义三个变量：

m = 用于训练的样本数
x^i = 第i个训练样本“输入”变量/特征量
​y^i = ​第i个训练样本“输出”变量/特征量
![6.2]()

如何给训练集下定义，先来看一下监督学习算法是怎么工作的.

算法的任务是 输出一个函数，用小写字母h表示,h表示假设(hypothesis)函数,这个假设函数的作用是把房子的大小作为输入变量x值,并输出想应房子的预测y值。

接下来人们的问题变成了如何表示假设函数

![6.3 training set->learning alogrithm]()

以及一个函数：

h_θ(x)=θ_0+θ_1*x               (1.1)
其中h是hypothesis（假设）的意思，当然，这个词在机器学习的当前情况下并不是特别准确。θ是参数，我们要做的是通过训练使得θ的表现效果更好。
这种模型被称为线性回归/单变量线性回归(Univariate linear regression)。

## 课时7  代价函数   08:12


## 课时8  代价函数（一） 11:09


## 课时9  代价函数（二） 08:48

## Parameter Learning

## 课时10  梯度下降  11:30


## 课时11  梯度下降知识点总结    11:50


## 课时12  线性回归的梯度下降    10:20



## 课时13  本章课程总结

